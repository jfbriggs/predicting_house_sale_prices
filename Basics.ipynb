{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Predicting House Sale Prices\n",
    "\n",
    "In this project, we'll be working with housing data for the city of Ames, Iowa from 2006 to 2010.  Information on the different columns contained in the dataset can be found [here](https://s3.amazonaws.com/dq-content/307/data_description.txt).\n",
    "\n",
    "We'll be building a linear regression model, fitting it, and cleaning the data/selecting features in an effort to create house sale price predictions.\n",
    "\n",
    "We will start by importing the data and setting up a pipeline of functions that will let us quickly iterate on different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Order</th>\n",
       "      <th>PID</th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>MS Zoning</th>\n",
       "      <th>Lot Frontage</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>Lot Shape</th>\n",
       "      <th>Land Contour</th>\n",
       "      <th>...</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Pool QC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>Misc Feature</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>Mo Sold</th>\n",
       "      <th>Yr Sold</th>\n",
       "      <th>Sale Type</th>\n",
       "      <th>Sale Condition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>526301100</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>141.0</td>\n",
       "      <td>31770</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>215000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>526350040</td>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>105000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>526351010</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Gar2</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>526353030</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>93.0</td>\n",
       "      <td>11160</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>244000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>527105010</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MnPrv</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>189900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Order        PID  MS SubClass MS Zoning  Lot Frontage  Lot Area Street  \\\n",
       "0      1  526301100           20        RL         141.0     31770   Pave   \n",
       "1      2  526350040           20        RH          80.0     11622   Pave   \n",
       "2      3  526351010           20        RL          81.0     14267   Pave   \n",
       "3      4  526353030           20        RL          93.0     11160   Pave   \n",
       "4      5  527105010           60        RL          74.0     13830   Pave   \n",
       "\n",
       "  Alley Lot Shape Land Contour  ... Pool Area Pool QC  Fence Misc Feature  \\\n",
       "0   NaN       IR1          Lvl  ...         0     NaN    NaN          NaN   \n",
       "1   NaN       Reg          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "2   NaN       IR1          Lvl  ...         0     NaN    NaN         Gar2   \n",
       "3   NaN       Reg          Lvl  ...         0     NaN    NaN          NaN   \n",
       "4   NaN       IR1          Lvl  ...         0     NaN  MnPrv          NaN   \n",
       "\n",
       "  Misc Val Mo Sold Yr Sold Sale Type  Sale Condition  SalePrice  \n",
       "0        0       5    2010       WD           Normal     215000  \n",
       "1        0       6    2010       WD           Normal     105000  \n",
       "2    12500       6    2010       WD           Normal     172000  \n",
       "3        0       4    2010       WD           Normal     244000  \n",
       "4        0       3    2010       WD           Normal     189900  \n",
       "\n",
       "[5 rows x 82 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing_data = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # Select just the numeric datatype columns to use in fitting our model\n",
    "    train_numeric = train.select_dtypes(include=[\"integer\", \"float\"])\n",
    "    test_numeric = test.select_dtypes(include=[\"integer\", \"float\"])\n",
    "    \n",
    "    # Remove SalePrice from our training/test features, given that it's our target column\n",
    "    features = train_numeric.columns.drop(\"SalePrice\")\n",
    "    \n",
    "    # Train the model using feature columns and generate SalePrice predictions\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train_numeric[features], train_numeric[\"SalePrice\"])\n",
    "    predictions = lr.predict(test_numeric[features])\n",
    "    \n",
    "    # Calculate RMSE value comparing predictions with existing SalePrice values in test data\n",
    "    rmse = np.sqrt(mean_squared_error(test_numeric[\"SalePrice\"], predictions))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "transformed_data = transform_features(housing_data)\n",
    "filtered_data = select_features(transformed_data)\n",
    "data_rmse = train_and_test(filtered_data)\n",
    "\n",
    "data_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Now we'll need to handle missing values.\n",
    "\n",
    "For all columns:\n",
    "- Drop any column with 5% or more missing values (for now)\n",
    "\n",
    "For text columns:\n",
    "- Drop any column with 1 more more missing values (for now)\n",
    "\n",
    "For numerical columns:\n",
    "- Fill missing values with the most common value in that column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Drop columns with 5% or more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Series object reflecting # of null values in each column\n",
    "num_missing = housing_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lot Frontage      490\n",
       "Alley            2732\n",
       "Fireplace Qu     1422\n",
       "Garage Type       157\n",
       "Garage Yr Blt     159\n",
       "Garage Finish     159\n",
       "Garage Qual       159\n",
       "Garage Cond       159\n",
       "Pool QC          2917\n",
       "Fence            2358\n",
       "Misc Feature     2824\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to columns that contain >5% missing values\n",
    "cols_to_drop = num_missing[(num_missing > len(housing_data) / 20)]\n",
    "cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove these columns from the dataset\n",
    "housing_data = housing_data.drop(cols_to_drop.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Drop text columns with 1 or more missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Bsmt Exposure     83\n",
       "BsmtFin Type 2    81\n",
       "BsmtFin Type 1    80\n",
       "Bsmt Qual         80\n",
       "Bsmt Cond         80\n",
       "Mas Vnr Type      23\n",
       "Electrical         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to text columns with 1+ missing values\n",
    "text_missing_counts = housing_data.select_dtypes(include=[\"object\"]).isnull().sum().sort_values(ascending=False)\n",
    "text_cols_to_drop = text_missing_counts[text_missing_counts > 0]\n",
    "text_cols_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop these columns from the dataset\n",
    "housing_data = housing_data.drop(text_cols_to_drop.index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Remaining numerical columns: fill in missing values with most common value in each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Mas Vnr Area      23\n",
       "Bsmt Half Bath     2\n",
       "Bsmt Full Bath     2\n",
       "Garage Cars        1\n",
       "BsmtFin SF 1       1\n",
       "Total Bsmt SF      1\n",
       "Bsmt Unf SF        1\n",
       "BsmtFin SF 2       1\n",
       "Garage Area        1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter to remaining columns with numerical datatypes, which have missing values\n",
    "num_cols_missing_counts = housing_data.select_dtypes(include = [\"float\", \"integer\"]).isnull().sum().sort_values(ascending=False)\n",
    "fixable_num_cols = num_cols_missing_counts[num_cols_missing_counts > 0]\n",
    "fixable_num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mas Vnr Area': 0.0,\n",
       " 'Bsmt Half Bath': 0.0,\n",
       " 'Bsmt Full Bath': 0.0,\n",
       " 'Garage Cars': 2.0,\n",
       " 'BsmtFin SF 1': 0.0,\n",
       " 'Total Bsmt SF': 0.0,\n",
       " 'Bsmt Unf SF': 0.0,\n",
       " 'BsmtFin SF 2': 0.0,\n",
       " 'Garage Area': 0.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine most common value for each column\n",
    "replacement_vals = housing_data[fixable_num_cols.index].mode().to_dict(orient=\"records\")[0]\n",
    "replacement_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values in with mode values above\n",
    "housing_data = housing_data.fillna(replacement_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure there are no missing values remaining in the dataset\n",
    "housing_data.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can use a few existing columns to create new features that better capture information that will be useful for our model.\n",
    "\n",
    "A couple of good options would be `\"Years Before Sale\"` (representing how long a house went after being built before it was sold) and `\"Years After Remod\"` (representing how many years it was, after a house was remodeled or added on to, before it was sold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2180   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_sold = housing_data[\"Yr Sold\"] - housing_data[\"Year Built\"]\n",
    "\n",
    "# Check for any negative values, which wouldn't be useful\n",
    "years_sold[years_sold < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1702   -1\n",
       "2180   -2\n",
       "2181   -1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "years_after_remod = housing_data[\"Yr Sold\"] - housing_data[\"Year Remod/Add\"]\n",
    "\n",
    "# CHeck for any negative values, which wouldn't be useful\n",
    "years_after_remod[years_after_remod < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish new columns for new features in dataset\n",
    "housing_data[\"Years Before Sale\"] = years_sold\n",
    "housing_data[\"Years After Remod/Add\"] = years_after_remod\n",
    "\n",
    "# Remove rows with negative values for these new features\n",
    "housing_data = housing_data.drop([1702, 2180, 2181], axis=0)\n",
    "\n",
    "# Remove original year columns, which are no longer needed\n",
    "housing__data = housing_data.drop([\"Year Built\", \"Year Remod/Add\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll move on to removing any additional columns that should be dropped:\n",
    "\n",
    "- Columns not useful for ML\n",
    "- Columns that leak data about the final sale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns not useful for ML (entry ID and order values)\n",
    "housing_data = housing_data.drop([\"Order\", \"PID\"], axis=1)\n",
    "\n",
    "# Drop columns that leak data about final sale\n",
    "housing_data = housing_data.drop([\"Yr Sold\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can update our `transform_features` function to carry out all of the dataset modifications we made above.  We'll re-write all 3 of our functions together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55275.367312413066"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    cols_to_drop = num_missing[(num_missing > len(df) / 20)].sort_values()\n",
    "    df = df.drop(cols_to_drop.index, axis=1)\n",
    "    \n",
    "    text_missing_counts = df.select_dtypes(include=[\"object\"]).isnull().sum().sort_values(ascending=False)\n",
    "    text_cols_to_drop = text_missing_counts[text_missing_counts > 0]\n",
    "    df = df.drop(text_cols_to_drop.index, axis=1)\n",
    "    \n",
    "    num_cols_missing_counts = df.select_dtypes(include = [\"float\", \"int\"]).isnull().sum().sort_values(ascending=False)\n",
    "    fixable_num_cols = num_cols_missing_counts[num_cols_missing_counts > 0]\n",
    "    replacement_vals = df[fixable_num_cols.index].mode().to_dict(orient=\"records\")[0]\n",
    "    df = df.fillna(replacement_vals)\n",
    "    \n",
    "    years_sold = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "    years_after_remod = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "    df[\"Years Before Sale\"] = years_sold\n",
    "    df[\"Years After Remod/Add\"] = years_after_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    \n",
    "    df = df.drop([\"Order\", \"PID\", \"Yr Sold\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\"], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # Select just the numeric datatype columns to use in fitting our model\n",
    "    train_numeric = train.select_dtypes(include=[\"integer\", \"float\"])\n",
    "    test_numeric = test.select_dtypes(include=[\"integer\", \"float\"])\n",
    "    \n",
    "    # Remove SalePrice from our training/test features, given that it's our target column\n",
    "    features = train_numeric.columns.drop(\"SalePrice\")\n",
    "    \n",
    "    # Train the model using feature columns and generate SalePrice predictions\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train_numeric[features], train_numeric[\"SalePrice\"])\n",
    "    predictions = lr.predict(test_numeric[features])\n",
    "    \n",
    "    # Calculate RMSE value comparing predictions with existing SalePrice values in test data\n",
    "    rmse = np.sqrt(mean_squared_error(test_numeric[\"SalePrice\"], predictions))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Re-read in housing data from original CSV and run functions\n",
    "housing_df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transformed_data = transform_features(housing_df)\n",
    "filtered_data = select_features(transformed_data)\n",
    "data_rmse = train_and_test(filtered_data)\n",
    "\n",
    "data_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Now that we've cleaned and transformed a lot of the features in the dataset, it's time to move on to feature selection for numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MS SubClass</th>\n",
       "      <th>Lot Area</th>\n",
       "      <th>Overall Qual</th>\n",
       "      <th>Overall Cond</th>\n",
       "      <th>Mas Vnr Area</th>\n",
       "      <th>BsmtFin SF 1</th>\n",
       "      <th>BsmtFin SF 2</th>\n",
       "      <th>Bsmt Unf SF</th>\n",
       "      <th>Total Bsmt SF</th>\n",
       "      <th>1st Flr SF</th>\n",
       "      <th>...</th>\n",
       "      <th>Wood Deck SF</th>\n",
       "      <th>Open Porch SF</th>\n",
       "      <th>Enclosed Porch</th>\n",
       "      <th>3Ssn Porch</th>\n",
       "      <th>Screen Porch</th>\n",
       "      <th>Pool Area</th>\n",
       "      <th>Misc Val</th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>Years Before Sale</th>\n",
       "      <th>Years After Remod/Add</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>31770</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>112.0</td>\n",
       "      <td>639.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>441.0</td>\n",
       "      <td>1080.0</td>\n",
       "      <td>1656</td>\n",
       "      <td>...</td>\n",
       "      <td>210</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>215000</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>11622</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>882.0</td>\n",
       "      <td>896</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>105000</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>14267</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>108.0</td>\n",
       "      <td>923.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>406.0</td>\n",
       "      <td>1329.0</td>\n",
       "      <td>1329</td>\n",
       "      <td>...</td>\n",
       "      <td>393</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>172000</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>11160</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1045.0</td>\n",
       "      <td>2110.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244000</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>13830</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>791.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>928</td>\n",
       "      <td>...</td>\n",
       "      <td>212</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>189900</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MS SubClass  Lot Area  Overall Qual  Overall Cond  Mas Vnr Area  \\\n",
       "0           20     31770             6             5         112.0   \n",
       "1           20     11622             5             6           0.0   \n",
       "2           20     14267             6             6         108.0   \n",
       "3           20     11160             7             5           0.0   \n",
       "4           60     13830             5             5           0.0   \n",
       "\n",
       "   BsmtFin SF 1  BsmtFin SF 2  Bsmt Unf SF  Total Bsmt SF  1st Flr SF  ...  \\\n",
       "0         639.0           0.0        441.0         1080.0        1656  ...   \n",
       "1         468.0         144.0        270.0          882.0         896  ...   \n",
       "2         923.0           0.0        406.0         1329.0        1329  ...   \n",
       "3        1065.0           0.0       1045.0         2110.0        2110  ...   \n",
       "4         791.0           0.0        137.0          928.0         928  ...   \n",
       "\n",
       "   Wood Deck SF  Open Porch SF  Enclosed Porch  3Ssn Porch  Screen Porch  \\\n",
       "0           210             62               0           0             0   \n",
       "1           140              0               0           0           120   \n",
       "2           393             36               0           0             0   \n",
       "3             0              0               0           0             0   \n",
       "4           212             34               0           0             0   \n",
       "\n",
       "   Pool Area  Misc Val  SalePrice  Years Before Sale  Years After Remod/Add  \n",
       "0          0         0     215000                 50                     50  \n",
       "1          0         0     105000                 49                     49  \n",
       "2          0     12500     172000                 52                     52  \n",
       "3          0         0     244000                 42                     42  \n",
       "4          0         0     189900                 13                     12  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_columns = transformed_data.select_dtypes(include=[\"float\", \"integer\"])\n",
    "num_columns.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the correlation coeffiecients (absolute values) for each feature column with `SalePrice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 2             0.006127\n",
       "Misc Val                 0.019273\n",
       "3Ssn Porch               0.032268\n",
       "Bsmt Half Bath           0.035875\n",
       "Low Qual Fin SF          0.037629\n",
       "Pool Area                0.068438\n",
       "MS SubClass              0.085128\n",
       "Overall Cond             0.101540\n",
       "Screen Porch             0.112280\n",
       "Kitchen AbvGr            0.119760\n",
       "Enclosed Porch           0.128685\n",
       "Bedroom AbvGr            0.143916\n",
       "Bsmt Unf SF              0.182751\n",
       "Lot Area                 0.267520\n",
       "2nd Flr SF               0.269601\n",
       "Bsmt Full Bath           0.276258\n",
       "Half Bath                0.284871\n",
       "Open Porch SF            0.316262\n",
       "Wood Deck SF             0.328183\n",
       "BsmtFin SF 1             0.439284\n",
       "Fireplaces               0.474831\n",
       "TotRms AbvGrd            0.498574\n",
       "Mas Vnr Area             0.506983\n",
       "Years After Remod/Add    0.534985\n",
       "Full Bath                0.546118\n",
       "Years Before Sale        0.558979\n",
       "1st Flr SF               0.635185\n",
       "Garage Area              0.641425\n",
       "Total Bsmt SF            0.644012\n",
       "Garage Cars              0.648361\n",
       "Gr Liv Area              0.717596\n",
       "Overall Qual             0.801206\n",
       "SalePrice                1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corr_coeffs = num_columns.corr()[\"SalePrice\"].abs().sort_values()\n",
    "abs_corr_coeffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now, we'll keep only the columns with coefficient values greater than 0.4 (an admittedly arbitrary choice).  Because we have a pipeline in place, it's easy to adjust/experiment with this value later and see which features result in a better cross validation score in the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BsmtFin SF 1             0.439284\n",
       "Fireplaces               0.474831\n",
       "TotRms AbvGrd            0.498574\n",
       "Mas Vnr Area             0.506983\n",
       "Years After Remod/Add    0.534985\n",
       "Full Bath                0.546118\n",
       "Years Before Sale        0.558979\n",
       "1st Flr SF               0.635185\n",
       "Garage Area              0.641425\n",
       "Total Bsmt SF            0.644012\n",
       "Garage Cars              0.648361\n",
       "Gr Liv Area              0.717596\n",
       "Overall Qual             0.801206\n",
       "SalePrice                1.000000\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corr_coeffs[abs_corr_coeffs > 0.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with less than 0.4 correlation with SalePrice\n",
    "transformed_data = transformed_data.drop(abs_corr_coeffs[abs_corr_coeffs < 0.4].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Variables\n",
    "\n",
    "Now we can take a look at which columns in our dataset should be converted to the `categorical` datatype.  We can start by creating a list of nominal variables, from the data, that are *meant* to be categorical:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A couple of questions we should now ask re: converting to categorical datatype:\n",
    "\n",
    "- If a categorical column has hundreds of unique values/categories, should we keep it?  When we dummy code this column, hundreds of new columns will need to be created in the dataframe.\n",
    "- Which columns are currently numerical but need to be encoded as categorical instead (because the numbers don't have any semantic meaning)?\n",
    "\n",
    "First, let's check: of the columns we're still working with at this point, which are included in the above nominal variable list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_cat_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in transformed_data.columns:\n",
    "        transform_cat_cols.append(col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll apply a cutoff of 10 unique categories per column (we can experiment with this threshold further, if desired)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establish counts of unique categories for selected columns\n",
    "num_cat_counts = transformed_data[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "\n",
    "# Drop columns with more than 10 unique categories\n",
    "transformed_data = transformed_data.drop(num_cat_counts[num_cat_counts > 10].index, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can convert the remaining text columns to category columns, and create our dummy columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select remaining text columns and convert to category\n",
    "text_cols = transformed_data.select_dtypes(include=[\"object\"])\n",
    "for col in text_cols:\n",
    "    transformed_data[col] = transformed_data[col].astype(\"category\")\n",
    "    \n",
    "# Create dummy columns and add back to dataframe\n",
    "transformed_data = pd.concat([\n",
    "    transformed_data,\n",
    "    pd.get_dummies(transformed_data.select_dtypes(include=[\"category\"]))\n",
    "], axis=1)\n",
    "\n",
    "# Finally, drop original text/category columns\n",
    "transformed_data = transformed_data.drop(text_cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, we can now update our functions; this time, we'll update `select_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33367.28718340374"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(df):\n",
    "    num_missing = df.isnull().sum()\n",
    "    cols_to_drop = num_missing[(num_missing > len(df) / 20)].sort_values()\n",
    "    df = df.drop(cols_to_drop.index, axis=1)\n",
    "    \n",
    "    text_missing_counts = df.select_dtypes(include=[\"object\"]).isnull().sum().sort_values(ascending=False)\n",
    "    text_cols_to_drop = text_missing_counts[text_missing_counts > 0]\n",
    "    df = df.drop(text_cols_to_drop.index, axis=1)\n",
    "    \n",
    "    num_cols_missing_counts = df.select_dtypes(include = [\"float\", \"int\"]).isnull().sum().sort_values(ascending=False)\n",
    "    fixable_num_cols = num_cols_missing_counts[num_cols_missing_counts > 0]\n",
    "    replacement_vals = df[fixable_num_cols.index].mode().to_dict(orient=\"records\")[0]\n",
    "    df = df.fillna(replacement_vals)\n",
    "    \n",
    "    years_sold = df[\"Yr Sold\"] - df[\"Year Built\"]\n",
    "    years_after_remod = df[\"Yr Sold\"] - df[\"Year Remod/Add\"]\n",
    "    df[\"Years Before Sale\"] = years_sold\n",
    "    df[\"Years After Remod/Add\"] = years_after_remod\n",
    "    df = df.drop([1702, 2180, 2181], axis=0)\n",
    "    df = df.drop([\"Year Built\", \"Year Remod/Add\"], axis=1)\n",
    "    \n",
    "    df = df.drop([\"Order\", \"PID\", \"Yr Sold\", \"Mo Sold\", \"Sale Condition\", \"Sale Type\"], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def select_features(df, coeff_threshold=0.4, cat_threshold=10):\n",
    "    numerical_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < coeff_threshold].index, axis=1)\n",
    "    \n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "    \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "\n",
    "    num_cat_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values() \n",
    "    df = df.drop(num_cat_counts[num_cat_counts > cat_threshold].index, axis=1)\n",
    "    \n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1).drop(text_cols,axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df[:1460]\n",
    "    test = df[1460:]\n",
    "    \n",
    "    # Select just the numeric datatype columns to use in fitting our model\n",
    "    train_numeric = train.select_dtypes(include=[\"integer\", \"float\"])\n",
    "    test_numeric = test.select_dtypes(include=[\"integer\", \"float\"])\n",
    "    \n",
    "    # Remove SalePrice from our training/test features, given that it's our target column\n",
    "    features = train_numeric.columns.drop(\"SalePrice\")\n",
    "    \n",
    "    # Train the model using feature columns and generate SalePrice predictions\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train_numeric[features], train_numeric[\"SalePrice\"])\n",
    "    predictions = lr.predict(test_numeric[features])\n",
    "    \n",
    "    # Calculate RMSE value comparing predictions with existing SalePrice values in test data\n",
    "    rmse = np.sqrt(mean_squared_error(test_numeric[\"SalePrice\"], predictions))\n",
    "    \n",
    "    return rmse\n",
    "\n",
    "# Re-read in housing data from original CSV and run functions\n",
    "housing_df = pd.read_csv(\"AmesHousing.tsv\", delimiter=\"\\t\")\n",
    "transformed_data = transform_features(housing_df)\n",
    "filtered_data = select_features(transformed_data)\n",
    "data_rmse = train_and_test(filtered_data)\n",
    "\n",
    "data_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Test\n",
    "\n",
    "Now for the final part of the pipeline, training and testing. When iterating on different features, using simple validation is a good idea. Let's add a parameter named k to our `train_and_test` function that controls the type of cross validation that occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25492.466794178024, 26300.590474204346, 36054.447982438134, 29105.211426713682]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "29238.179169383548"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_test(df, k=0):\n",
    "    numeric_df = df.select_dtypes(include=['integer', 'float'])\n",
    "    features = numeric_df.columns.drop(\"SalePrice\")\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    # If k is 0, perform holdout validation\n",
    "    if k == 0:\n",
    "        \n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "\n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions = lr.predict(test[features])\n",
    "        mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "\n",
    "        return rmse\n",
    "    \n",
    "    # If k is 1, perform simple cross validation\n",
    "    if k == 1:\n",
    "        \n",
    "        # Randomize all rows using (frac=1) from \"df\" and return\n",
    "        shuffled_df = df.sample(frac=1, )\n",
    "        train = df[:1460]\n",
    "        test = df[1460:]\n",
    "        \n",
    "        lr.fit(train[features], train[\"SalePrice\"])\n",
    "        predictions_one = lr.predict(test[features])        \n",
    "        \n",
    "        mse_one = mean_squared_error(test[\"SalePrice\"], predictions_one)\n",
    "        rmse_one = np.sqrt(mse_one)\n",
    "        \n",
    "        lr.fit(test[features], test[\"SalePrice\"])\n",
    "        predictions_two = lr.predict(train[features])        \n",
    "       \n",
    "        mse_two = mean_squared_error(train[\"SalePrice\"], predictions_two)\n",
    "        rmse_two = np.sqrt(mse_two)\n",
    "        \n",
    "        avg_rmse = np.mean([rmse_one, rmse_two])\n",
    "        print(rmse_one)\n",
    "        print(rmse_two)\n",
    "        return avg_rmse\n",
    "    \n",
    "    \n",
    "    # If k > 1, use KFold to perform k-fold cross validation\n",
    "    else:\n",
    "        \n",
    "        kf = KFold(n_splits=k, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        print(rmse_values)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return avg_rmse\n",
    "        \n",
    "rmse = train_and_test(filtered_data, k=4)\n",
    "\n",
    "rmse        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "A couple of potential next steps:\n",
    "\n",
    "- Continuing iteration on feature engineering: researching additional approaches to feature engineering online for housing data\n",
    "- Improving feature selection: researching better ways of doing feature selection with categorical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
